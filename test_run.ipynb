{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"MUJOCO_GL\"] = \"osmesa\"\n",
    "# os.environ[\"MUJOCO_GL\"] = \"glfw\"\n",
    "\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dreamer.algorithms.dreamer import Dreamer\n",
    "from dreamer.algorithms.plan2explore import Plan2Explore\n",
    "from dreamer.utils.utils import load_config, get_base_directory\n",
    "from dreamer.envs.envs import make_dmc_env, make_atari_env, get_env_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load config and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_arg = \"p2e-dmc-walker-walk\"\n",
    "# device = None\n",
    "device =\"cuda:5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device:  cuda:5\n",
      "local: cuda:5, args:cuda:5\n",
      "log_dir_path:  /root/sharespace2/plan2explore/torch-ver/SimpleDreamer/runs/2023-10-27_20-13-23_batch-15-walker-walk\n"
     ]
    }
   ],
   "source": [
    "config = load_config(config_arg)\n",
    "\n",
    "if device is None:\n",
    "    device = config.operation.device\n",
    "else:\n",
    "    config[\"operation\"][\"device\"] = device\n",
    "print(\"use device: \", device)\n",
    "\n",
    "print(\"local: {}, args:{}\".format(device, config.operation.device))\n",
    "\n",
    "writer = None\n",
    "\n",
    "log_dir_base_path = os.path.join(get_base_directory(), \"runs\")\n",
    "log_dir_name = \"2023-10-27_20-13-23_batch-15-walker-walk\"\n",
    "log_dir = os.path.join(log_dir_base_path, log_dir_name)\n",
    "print(\"log_dir_path: \", log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/envs/registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/dmc2gym/wrappers.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dim = np.int(np.prod(s.shape))\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "if config.environment.benchmark == \"atari\":\n",
    "    env = make_atari_env(\n",
    "        task_name=config.environment.task_name,\n",
    "        seed=config.environment.seed,\n",
    "        height=config.environment.height,\n",
    "        width=config.environment.width,\n",
    "        skip_frame=config.environment.frame_skip,\n",
    "        pixel_norm=config.environment.pixel_norm,\n",
    "    )\n",
    "elif config.environment.benchmark == \"dmc\":\n",
    "    env = make_dmc_env(\n",
    "        domain_name=config.environment.domain_name,\n",
    "        task_name=config.environment.task_name,\n",
    "        seed=config.environment.seed,\n",
    "        visualize_reward=config.environment.visualize_reward,\n",
    "        from_pixels=config.environment.from_pixels,\n",
    "        height=config.environment.height,\n",
    "        width=config.environment.width,\n",
    "        frame_skip=config.environment.frame_skip,\n",
    "        pixel_norm=config.environment.pixel_norm,\n",
    "    )\n",
    "obs_shape, discrete_action_bool, action_size = get_env_infos(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the initialization of agent\n",
      "load the model from /root/sharespace2/plan2explore/torch-ver/SimpleDreamer/runs/2023-10-27_20-13-23_batch-15-walker-walk/plan2explore_800.pth\n",
      "Done loading the model\n"
     ]
    }
   ],
   "source": [
    "if config.algorithm == \"dreamer-v1\":\n",
    "    agent = Dreamer(obs_shape, discrete_action_bool, action_size, writer, device, config, log_dir)\n",
    "elif config.algorithm == \"plan2explore\":\n",
    "    agent = Plan2Explore(obs_shape, discrete_action_bool, action_size, writer, device, config, log_dir)\n",
    "print(\"finish the initialization of agent\")\n",
    "\n",
    "model_path = agent.generate_model_path(itr=800, save_dir=log_dir)\n",
    "agent.load_model(model_path)\n",
    "\n",
    "print(\"Done loading the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the model in test environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
      "  logger.warn(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/root/.pyenv/versions/3.8.0/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.90s/it]\n"
     ]
    }
   ],
   "source": [
    "result_dict = agent.validation_interaction(agent.intrinsic_actor, env, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3, 64, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_dict[\"0\"][\"obs_lst\"].shape\n",
    "# result_dict[\"0\"][\"reward_lst\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46862745098039216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(result_dict[\"0\"][\"obs_lst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/sharespace2/plan2explore/torch-ver/SimpleDreamer/runs/2023-10-27_20-13-23_batch-15-walker-walk/test.mp4\n"
     ]
    }
   ],
   "source": [
    "# import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "episode_key = \"0\"\n",
    "\n",
    "# convert the observation\n",
    "obs_lst = np.add(result_dict[episode_key][\"obs_lst\"].transpose(0, 2, 3, 1), 0.5)\n",
    "\n",
    "reward_lst = result_dict[episode_key][\"reward_lst\"]\n",
    "episode_length = obs_lst.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(3*1, 3*1))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "def plot(t):\n",
    "    plt.cla()\n",
    "    ax1.cla()\n",
    "    ax1.imshow(obs_lst[t])\n",
    "    ax1.set_title(\"time: {}, reward: {:.5f}\".format(t, reward_lst[t]))\n",
    "    ax1.set_axis_off()\n",
    "\n",
    "anim = FuncAnimation(fig, plot, frames=episode_length, interval=100)\n",
    "save_path = os.path.join(log_dir, \"test.mp4\")\n",
    "print(save_path)\n",
    "anim.save(save_path, writer='ffmpeg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
